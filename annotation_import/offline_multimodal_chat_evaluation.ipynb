{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eZsDkk8eNzq"
      },
      "source": [
        "<td>   <a target=\"_blank\" href=\"https://labelbox.com\" ><img src=\"https://labelbox.com/blog/content/images/2021/02/logo-v4.svg\" width=256/></a></td>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WhqOL9deNzs"
      },
      "source": [
        "<td>\n",
        "<a href=\"https://colab.research.google.com/github/Labelbox/labelbox-python/blob/develop/examples/annotation_import/conversational_LLM.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "</td>\n",
        "\n",
        "<td>\n",
        "<a href=\"https://github.com/Labelbox/labelbox-python/tree/develop/examples/annotation_import/offline_multimodal_chat_evaluation.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://img.shields.io/badge/GitHub-100000?logo=github&logoColor=white\" alt=\"GitHub\"></a>\n",
        "</td>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qUvNiiY_qhI"
      },
      "source": [
        "# Offline multimodal chat evaluation annotation import\n",
        "\n",
        "This notebook provides examples of each annotation type supported by the offline multimodal chat evalution project and walks through the complete process of importing annotations as prelabels (model assisted labeling) or ground truth."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBcUvSRTeNzt"
      },
      "source": [
        "# Set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ty51UFk7eNzt",
        "outputId": "0c1cbc21-d116-45ab-e53b-7287fdcc34ce"
      },
      "outputs": [],
      "source": [
        "%pip install -q \"labelbox[data]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWt-qbgSeNzt"
      },
      "outputs": [],
      "source": [
        "import labelbox as lb\n",
        "import labelbox.types as lb_types\n",
        "import uuid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDTOgrh6eNzu"
      },
      "source": [
        "# Replace with your API key\n",
        "\n",
        "Replace the value of `API_KEY` with a valid [API key]([ref:create-api-key](https://docs.labelbox.com/reference/create-api-key)  to connect to the Labelbox client."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJP9wgQ9eNzu"
      },
      "outputs": [],
      "source": [
        "API_KEY = \"\"\n",
        "client = lb.Client(api_key=API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NehiK5inktza"
      },
      "outputs": [],
      "source": [
        "from labelbox.types import (\n",
        "    Label,\n",
        "    MessageEvaluationTaskAnnotation,\n",
        "    MessageInfo,\n",
        "    MessageMultiSelectionTask,\n",
        "    MessageRankingTask,\n",
        "    MessageSingleSelectionTask,\n",
        "    OrderedMessageInfo,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sffdTeveNzu"
      },
      "source": [
        "# Supported annotations for multimodal chat evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbyg4Ea0eNzu"
      },
      "source": [
        "### Tool: Message ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EfbgAYZheNzu",
        "outputId": "e9a93907-9b28-467e-d8a4-8cb4565d2c01"
      },
      "outputs": [],
      "source": [
        "message_ranking_annotation = lb_types.MessageEvaluationTaskAnnotation(\n",
        "    name=\"Message ranking\",\n",
        "    value=MessageRankingTask(\n",
        "        parent_message_id=\"clxfznjb800073b6v43ppx9ca\",\n",
        "        ranked_messages=[\n",
        "            OrderedMessageInfo(\n",
        "                message_id=\"clxfzocbm00083b6v8vczsept\",\n",
        "                model_config_name=\"GPT 4 with temperature 0.7\",\n",
        "                order=1,\n",
        "            ),\n",
        "            OrderedMessageInfo(\n",
        "                message_id=\"clxfzocbm00093b6vx4ndisub\",\n",
        "                model_config_name=\"GPT 5\",\n",
        "                order=2,\n",
        "            ),\n",
        "        ],\n",
        "    ),\n",
        ")\n",
        "\n",
        "message_ranking_annotation_ndjson = {\n",
        "    \"name\": \"model output multi ranking\",\n",
        "    \"messageEvaluationTask\": {\n",
        "        \"format\": \"message-ranking\",\n",
        "        \"data\": {\n",
        "            \"parentMessageId\": \"clxfzhair00023b6vb607bqo6\",\n",
        "            \"rankedMessages\": [\n",
        "                {\n",
        "                    \"messageId\": \"clxfzi3r400063b6vuaeajylo\",\n",
        "                    \"modelConfigName\": \"GPT 4 with temperature 0.7\",\n",
        "                    \"order\": 2,\n",
        "                },\n",
        "                {\n",
        "                    \"messageId\": \"clxfzi3r400053b6vm5udpdgo\",\n",
        "                    \"modelConfigName\": \"GPT 5\",\n",
        "                    \"order\": 1,\n",
        "                },\n",
        "            ],\n",
        "        },\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdR7rFlMCQcl"
      },
      "source": [
        "### Tool: Single message selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pMtx3Khi6KFb",
        "outputId": "31ac7563-5474-491c-cda5-30da159fb57a"
      },
      "outputs": [],
      "source": [
        "single_message_selection_annotation = lb_types.MessageEvaluationTaskAnnotation(\n",
        "    name=\"Single message selection\",\n",
        "    value=MessageSingleSelectionTask(\n",
        "        message_id=\"clxfzi3r400053b6vm5udpdgo\",\n",
        "        parent_message_id=\"clxfzhair00023b6vb607bqo6\",\n",
        "        model_config_name=\"GPT 4 with temperature 0.7\",\n",
        "    ),\n",
        ")\n",
        "single_message_selection_annotation_ndjson = {\n",
        "    \"name\": \"Single message selection\",\n",
        "    \"messageEvaluationTask\": {\n",
        "        \"format\": \"message-single-selection\",\n",
        "        \"data\": {\n",
        "            \"messageId\": \"clxfzi3r400053b6vm5udpdgo\",\n",
        "            \"parentMessageId\": \"clxfzhair00023b6vb607bqo6\",\n",
        "            \"modelConfigName\": \"GPT 4 with temperature 0.7\",\n",
        "        },\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miDD2em0CWsb"
      },
      "source": [
        "### Tool: Multiple message selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDFnlbVGjcPm"
      },
      "outputs": [],
      "source": [
        "multiple_message_selection_annotation = lb_types.MessageEvaluationTaskAnnotation(\n",
        "    name=\"Multi message selection\",\n",
        "    value=MessageMultiSelectionTask(\n",
        "        parent_message_id=\"clxfzhair00023b6vb607bqo6\",\n",
        "        selected_messages=[\n",
        "            MessageInfo(\n",
        "                message_id=\"clxfzi3r400063b6vuaeajylo\",\n",
        "                model_config_name=\"GPT 4 with temperature 0.7\",\n",
        "            ),\n",
        "            MessageInfo(\n",
        "                message_id=\"clxfzi3r400053b6vm5udpdgo\",\n",
        "                model_config_name=\"GPT 5\",\n",
        "            ),\n",
        "        ],\n",
        "    ),\n",
        ")\n",
        "multiple_message_selection_annotation_ndjson = {\n",
        "    \"name\": \"Multi message selection\",\n",
        "    \"messageEvaluationTask\": {\n",
        "        \"format\": \"message-multi-selection\",\n",
        "        \"data\": {\n",
        "            \"parentMessageId\": \"clxfzhair00023b6vb607bqo6\",\n",
        "            \"selectedMessages\": [\n",
        "                {\n",
        "                    \"messageId\": \"clxfzi3r400063b6vuaeajylo\",\n",
        "                    \"modelConfigName\": \"GPT 4 with temperature 0.7\",\n",
        "                },\n",
        "                {\n",
        "                    \"messageId\": \"clxfzi3r400053b6vm5udpdgo\",\n",
        "                    \"modelConfigName\": \"GPT 5\",\n",
        "                },\n",
        "            ],\n",
        "        },\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmRq_uUWeNzu"
      },
      "source": [
        "### Classification: Radio (single-choice)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHNXIWSOeNzu"
      },
      "outputs": [],
      "source": [
        "radio_annotation = lb_types.ClassificationAnnotation(\n",
        "    name=\"Choose the best response\",\n",
        "    value=lb_types.Radio(answer=lb_types.ClassificationAnswer(\n",
        "        name=\"Response B\")),\n",
        ")\n",
        "\n",
        "radio_annotation_ndjson = {\n",
        "    \"name\": \"Choose the best response\",\n",
        "    \"answer\": {\n",
        "        \"name\": \"Response B\"\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTUpRGWHeNzu"
      },
      "source": [
        "### Classification: Free-form text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNsiybbveNzu"
      },
      "outputs": [],
      "source": [
        "text_annotation = lb_types.ClassificationAnnotation(\n",
        "    name=\"Provide a reason for your choice\",\n",
        "    value=lb_types.Text(answer=\"the answer to the text questions right here\"),\n",
        ")\n",
        "\n",
        "text_annotation_ndjson = {\n",
        "    \"name\": \"Provide a reason for your choice\",\n",
        "    \"answer\": \"This is the more concise answer\",\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55D5csZpeNzv"
      },
      "source": [
        "### Classification: Checklist (multi-choice)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrpPFANVeNzv"
      },
      "outputs": [],
      "source": [
        "checklist_annotation = lb_types.ClassificationAnnotation(\n",
        "    name=\"checklist_convo\",  # must match your ontology feature\"s name\n",
        "    value=lb_types.Checklist(answer=[\n",
        "        lb_types.ClassificationAnswer(name=\"first_checklist_answer\"),\n",
        "        lb_types.ClassificationAnswer(name=\"second_checklist_answer\"),\n",
        "    ]),\n",
        "    message_id=\"clxfznjb800073b6v43ppx9ca\",  # Message specific annotation\n",
        ")\n",
        "\n",
        "checklist_annotation_ndjson = {\n",
        "    \"name\": \"checklist_convo\",\n",
        "    \"answers\": [\n",
        "        {\n",
        "            \"name\": \"first_checklist_answer\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"second_checklist_answer\"\n",
        "        },\n",
        "    ],\n",
        "    \"messageId\": \"clxfznjb800073b6v43ppx9ca\",\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLj37R6reNzv"
      },
      "source": [
        "## Step 1: Import data rows into Catalog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "x6KR44tAeNzv",
        "outputId": "94e5185c-2ed3-4c6f-c5e2-3d253955775d"
      },
      "outputs": [],
      "source": [
        "mmc_asset = \"https://storage.googleapis.com/labelbox-datasets/conversational_model_evaluation_sample/offline-model-chat-evaluation.json\"\n",
        "global_key = \"offline-multimodal_chat_evaluation\"\n",
        "\n",
        "# Upload data rows\n",
        "convo_data = {\n",
        "    \"row_data\": mmc_asset,\n",
        "    \"global_key\": global_key\n",
        "}\n",
        "\n",
        "# Create a dataset\n",
        "dataset = client.create_dataset(name=\"offline-multimodal_chat_evaluation_demo\")\n",
        "# Create a datarow\n",
        "task = dataset.create_data_rows([convo_data])\n",
        "task.wait_till_done()\n",
        "print(\"Errors:\",task.errors)\n",
        "print(\"Failed data rows:\", task.failed_data_rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw2288YNeNzv"
      },
      "source": [
        "## Step 2: Create/select an Ontology"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2dqJApaeNzv"
      },
      "outputs": [],
      "source": [
        "ontology_builder = lb.OntologyBuilder(\n",
        "    tools=[\n",
        "        lb.Tool(\n",
        "            tool=lb.Tool.Type.MESSAGE_SINGLE_SELECTION,\n",
        "            name=\"Single message selection\",\n",
        "        ),\n",
        "        lb.Tool(\n",
        "            tool=lb.Tool.Type.MESSAGE_MULTI_SELECTION,\n",
        "            name=\"Multi message selection\",\n",
        "        ),\n",
        "        lb.Tool(tool=lb.Tool.Type.MESSAGE_RANKING, name=\"Message ranking\"),\n",
        "    ],\n",
        "  classifications=[\n",
        "    lb.Classification(\n",
        "      class_type=lb.Classification.Type.RADIO,\n",
        "      scope=lb.Classification.Scope.GLOBAL,\n",
        "      name=\"Choose the best response\",\n",
        "      options=[lb.Option(value=\"Response A\"), lb.Option(value=\"Response B\"), lb.Option(value=\"Tie\")]\n",
        "    ),\n",
        "    lb.Classification(\n",
        "      class_type=lb.Classification.Type.TEXT,\n",
        "      name=\"Provide a reason for your choice\"\n",
        "    ),\n",
        "    lb.Classification(\n",
        "      class_type=lb.Classification.Type.CHECKLIST,\n",
        "      scope=lb.Classification.Scope.INDEX,\n",
        "      name=\"checklist_convo\",\n",
        "      options=[\n",
        "        lb.Option(value=\"first_checklist_answer\"),\n",
        "        lb.Option(value=\"second_checklist_answer\")\n",
        "      ]\n",
        "    )\n",
        "  ]\n",
        ")\n",
        "# Create ontology\n",
        "ontology = client.create_ontology(\n",
        "    \"MMC ontology\",\n",
        "    ontology_builder.asdict(),\n",
        "    media_type=lb.MediaType.Conversational,\n",
        "    ontology_kind=lb.OntologyKind.ModelEvaluation,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9L1kSnheNzv"
      },
      "source": [
        "## Step 3: Create a labeling project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qQm7Bh5eNzv"
      },
      "outputs": [],
      "source": [
        "# Create Labelbox project\n",
        "project = client.create_offline_model_evaluation_project(\n",
        "    name=\"Offline MMC Import Demo\",\n",
        "    description=\"<project_description>\",  # optional\n",
        "    media_type=lb.MediaType.Conversational,\n",
        ")\n",
        "\n",
        "# Setup your ontology\n",
        "project.connect_ontology(\n",
        "    ontology)  # Connect your ontology and editor to your project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFBbimOPeNzw"
      },
      "source": [
        "## Step 4: Send a batch of data rows to the project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DBNTNIYGeNzw",
        "outputId": "f6089d9e-4e64-4a59-c09e-3078ec80afa8"
      },
      "outputs": [],
      "source": [
        "# Create a batch to send to your project\n",
        "batch = project.create_batch(\n",
        "    \"first-batch-convo-demo\",  # Each batch in a project must have a unique name\n",
        "    global_keys=[\n",
        "        global_key\n",
        "    ],  # Paginated collection of data row objects, list of data row ids or global keys\n",
        "    priority=5,  # priority between 1(Highest) - 5(lowest)\n",
        ")\n",
        "\n",
        "print(\"Batch: \", batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBWD5t5EeNzw"
      },
      "source": [
        "## Step 5: Create the annotations payload"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbD74v7neNzw"
      },
      "source": [
        "Python annotation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "op5i6cNQeNzw"
      },
      "outputs": [],
      "source": [
        "label = []\n",
        "label.append(\n",
        "    lb_types.Label(\n",
        "        data={\"global_key\": global_key},\n",
        "        annotations=[\n",
        "            message_ranking_annotation,\n",
        "            single_message_selection_annotation,\n",
        "            multiple_message_selection_annotation,\n",
        "            text_annotation,\n",
        "            checklist_annotation,\n",
        "            radio_annotation,\n",
        "        ],\n",
        "    ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0SiIp1reNzw"
      },
      "source": [
        "NDJSON annotation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "collapsed": true,
        "id": "-k55rNxQeNzw",
        "outputId": "37ba73a9-0e9a-408e-dfbc-fe03492f4c65"
      },
      "outputs": [],
      "source": [
        "label_ndjson = []\n",
        "for annotations in [\n",
        "        message_ranking_annotation_ndjson,\n",
        "        single_message_selection_annotation_ndjson,\n",
        "        multiple_message_selection_annotation_ndjson,\n",
        "        text_annotation_ndjson,\n",
        "        checklist_annotation_ndjson,\n",
        "        radio_annotation_ndjson,\n",
        "]:\n",
        "    annotations.update({\"dataRow\": {\"globalKey\": global_key}})\n",
        "    label_ndjson.append(annotations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nkg5VDU7eNzw"
      },
      "source": [
        "## Step 6: import annotations to a project as pre-labels or ground truth labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MzijtA3eNzw"
      },
      "source": [
        "### Import as prelabels (model assisted labeling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "f0Hu2UsQeNzw",
        "outputId": "e91ce10a-94ab-4aef-e3ce-2b1b30a644c7"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "upload_job = lb.MALPredictionImport.create_from_objects(\n",
        "    client=client,\n",
        "    project_id=project.uid,\n",
        "    name=f\"mal_job-{str(uuid.uuid4())}\",\n",
        "    predictions=label,\n",
        ")\n",
        "\n",
        "upload_job.wait_until_done()\n",
        "print(\"Errors:\", upload_job.errors)\n",
        "print(\"Status of uploads: \", upload_job.statuses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL9aD-aleNzw"
      },
      "source": [
        "### Import as ground truth labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1k2F_DNKeNzz",
        "outputId": "23517a11-9b5d-4ab5-ad52-0907bd6bc7b5"
      },
      "outputs": [],
      "source": [
        "upload_job = lb.LabelImport.create_from_objects(\n",
        "    client=client,\n",
        "    project_id=project.uid,\n",
        "    name=\"label_import_job\" + str(uuid.uuid4()),\n",
        "    labels=label,\n",
        ")\n",
        "\n",
        "upload_job.wait_until_done()\n",
        "print(\"Errors:\", upload_job.errors)\n",
        "print(\"Status of uploads: \", upload_job.statuses)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
